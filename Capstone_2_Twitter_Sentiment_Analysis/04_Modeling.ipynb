{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f4429d",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - 04 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117bd73",
   "metadata": {},
   "source": [
    "The stock market is a focus for investors to maximize their potential profits and consequently, the interest shown from the technical and financial sides in stock market prediction is always on the rise. However, stock market prediction is a problem known for its challenging nature due to its dependency on diverse factors that affect the market, these factors are unpredictable and cannot be taken into consideration such as political variables, and social media effects such as twitter on the stock market.\n",
    "\n",
    "In this final part of this project, we will combine the stock data and its features, with vectorized representation of the tweets for the month of December 2022 to predict whether or not the adjusted closing price at the end of a trading-day is greater than or less than the previous trading-day. Models run are Logistic Regression, KNN, SVM, Random Forest, and K-means Clustering.\n",
    "\n",
    "Two types of predictions: \n",
    "1. Using overall daily tweet sentiment scores to predict adjusted closing price\n",
    "2. Using vectorized representation of tweets to predict adjusted closing price\n",
    "\n",
    "**Link(s) to previous notebook(s)**: \\\n",
    "00_Historical_Data_2014: https://github.com/parisvu07/Springboard_Data_Science/tree/main/Capstone_2_Twitter_Sentiment_Analysis \\\n",
    "01_Data_Wrangling:\n",
    "https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/01_Data_Wrangling.ipynb \\\n",
    "02_Exploratory_Data_Analysis: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/02_Exploratory_Data_Analysis.ipynb \\\n",
    "03_Preprocessing_and_Training_Data: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/03_Preprocessing_and_Training_Data.ipynb\n",
    "\n",
    "Quick fix for \"Unable to render rich display\": copy and paste the notebook link to https://nbviewer.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6f3a3",
   "metadata": {},
   "source": [
    "## 4.1 Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11511d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import spacy\n",
    "np.random.seed(42)\n",
    "\n",
    "from gensim.models import KeyedVectors \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da83c4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>%_change_Open</th>\n",
       "      <th>%_change_High</th>\n",
       "      <th>%_change_Low</th>\n",
       "      <th>%_change_Close</th>\n",
       "      <th>%_change_Volume</th>\n",
       "      <th>twitter_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>-1.518116</td>\n",
       "      <td>-0.757731</td>\n",
       "      <td>-0.654803</td>\n",
       "      <td>-0.337132</td>\n",
       "      <td>-8.144516</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1.240064</td>\n",
       "      <td>1.972972</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>-0.798317</td>\n",
       "      <td>5.162925</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>-0.473707</td>\n",
       "      <td>-2.398619</td>\n",
       "      <td>-2.641151</td>\n",
       "      <td>-2.536999</td>\n",
       "      <td>-5.955854</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>-3.318151</td>\n",
       "      <td>-2.668030</td>\n",
       "      <td>-1.352874</td>\n",
       "      <td>-1.378491</td>\n",
       "      <td>7.715304</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  stock_volume  %_change_Open  %_change_High  \\\n",
       "Dates                                                                \n",
       "2022-12-01  148.309998      71250400            NaN            NaN   \n",
       "2022-12-02  147.809998      65447400      -1.518116      -0.757731   \n",
       "2022-12-05  146.630005      68826400       1.240064       1.972972   \n",
       "2022-12-06  142.910004      64727200      -0.473707      -2.398619   \n",
       "2022-12-07  140.940002      69721100      -3.318151      -2.668030   \n",
       "\n",
       "            %_change_Low  %_change_Close  %_change_Volume  twitter_volume  \n",
       "Dates                                                                      \n",
       "2022-12-01           NaN             NaN              NaN            1451  \n",
       "2022-12-02     -0.654803       -0.337132        -8.144516            1551  \n",
       "2022-12-05      0.082396       -0.798317         5.162925            1738  \n",
       "2022-12-06     -2.641151       -2.536999        -5.955854            2072  \n",
       "2022-12-07     -1.352874       -1.378491         7.715304            1912  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing stock data from notebook \"02_Exploratory_Data_Analysis\"\n",
    "stock_data = pd.read_csv('03_stock_data.csv', encoding='latin-1')\n",
    "stock_data = stock_data.set_index('Dates')\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf864f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>likes</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:43</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>New Yearâs food traditions around the world</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>new yearâ  food tradition  around the world</td>\n",
       "      <td>['new', 'yearâ', 'food', 'tradition', 'around'...</td>\n",
       "      <td>new yearâ food tradition around world</td>\n",
       "      <td>['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...</td>\n",
       "      <td>[-2.31491498e-01  6.51704955e-02  1.90656667e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:32</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Entries &amp;amp; exits Daily! \\nDiscord link belo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 1, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entrie   amp  exit  daily  \\ndi cord link belo...</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>entrie amp exit daily di cord link belowð</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>[ 3.40714295e-02  9.44165736e-02 -8.08280031e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:28</td>\n",
       "      <td>StockJobberOG</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>$AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aapl  m ft   py  t la  amzn  brk b\\n\\n</td>\n",
       "      <td>['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...</td>\n",
       "      <td>aapl ft py la amzn brk b</td>\n",
       "      <td>['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']</td>\n",
       "      <td>[-0.11772024  0.12171325  0.28293075 -0.131354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:11</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>The biggest â and maybe the best â financi...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>the bigge t â and maybe the be t â financi...</td>\n",
       "      <td>['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...</td>\n",
       "      <td>bigge â maybe â financial olution hould u ...</td>\n",
       "      <td>['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...</td>\n",
       "      <td>[-5.57102112e-02  1.48102408e-01  7.54352845e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:28:29</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td># Chatroom interms of \\n\\nalert,calls,Analysis...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 1, '$ ...</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>chatroom interm  of \\n\\nalert call  analy i ...</td>\n",
       "      <td>['chatroom', 'interm', 'of', 'alert', 'call', ...</td>\n",
       "      <td>chatroom interm alert call analy</td>\n",
       "      <td>['chatroom', 'interm', 'alert', 'call', 'analy']</td>\n",
       "      <td>[-1.83531667e-01  2.19245007e-01 -1.40175003e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates      Time            user  likes           source  \\\n",
       "0  2022-12-30  20:29:43  LlcBillionaire      0  Twitter Web App   \n",
       "1  2022-12-30  20:29:32      skitontop1      0  Twitter Web App   \n",
       "2  2022-12-30  20:29:28   StockJobberOG      0  Twitter Web App   \n",
       "3  2022-12-30  20:29:11  LlcBillionaire      0  Twitter Web App   \n",
       "4  2022-12-30  20:28:29      skitontop1      0  Twitter Web App   \n",
       "\n",
       "                                                text  Subjectivity  Polarity  \\\n",
       "0     New Yearâs food traditions around the world       0.454545  0.136364   \n",
       "1  Entries &amp; exits Daily! \\nDiscord link belo...      0.500000  0.300000   \n",
       "2            $AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n      0.000000  0.000000   \n",
       "3  The biggest â and maybe the best â financi...      0.150000  0.500000   \n",
       "4  # Chatroom interms of \\n\\nalert,calls,Analysis...      1.000000  0.600000   \n",
       "\n",
       "   Analysis  Sentiment  ...  mention_count  \\\n",
       "0  Positive        1.0  ...              0   \n",
       "1  Positive        1.0  ...              0   \n",
       "2   Neutral        0.0  ...              0   \n",
       "3  Positive        1.0  ...              0   \n",
       "4  Positive        1.0  ...              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.714286   \n",
       "1  {'! count': 1, '\" count': 0, '# count': 0, '$ ...        7.428571   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.166667   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.200000   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 1, '$ ...        9.200000   \n",
       "\n",
       "  unique_vs_words  stopwords_vs_words  \\\n",
       "0             1.0            0.142857   \n",
       "1             1.0            0.000000   \n",
       "2             1.0            0.000000   \n",
       "3             0.9            0.433333   \n",
       "4             1.0            0.200000   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0     new yearâ  food tradition  around the world    \n",
       "1  entrie   amp  exit  daily  \\ndi cord link belo...   \n",
       "2             aapl  m ft   py  t la  amzn  brk b\\n\\n   \n",
       "3  the bigge t â and maybe the be t â financi...   \n",
       "4    chatroom interm  of \\n\\nalert call  analy i ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['new', 'yearâ', 'food', 'tradition', 'around'...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2  ['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...   \n",
       "3  ['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...   \n",
       "4  ['chatroom', 'interm', 'of', 'alert', 'call', ...   \n",
       "\n",
       "                             tweet_without_stopwords  \\\n",
       "0            new yearâ food tradition around world   \n",
       "1       entrie amp exit daily di cord link belowð   \n",
       "2                           aapl ft py la amzn brk b   \n",
       "3  bigge â maybe â financial olution hould u ...   \n",
       "4                   chatroom interm alert call analy   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  ['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2     ['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']   \n",
       "3  ['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...   \n",
       "4   ['chatroom', 'interm', 'alert', 'call', 'analy']   \n",
       "\n",
       "                                                 vec  \n",
       "0  [-2.31491498e-01  6.51704955e-02  1.90656667e-...  \n",
       "1  [ 3.40714295e-02  9.44165736e-02 -8.08280031e-...  \n",
       "2  [-0.11772024  0.12171325  0.28293075 -0.131354...  \n",
       "3  [-5.57102112e-02  1.48102408e-01  7.54352845e-...  \n",
       "4  [-1.83531667e-01  2.19245007e-01 -1.40175003e-...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing tweet data from previous notebook \"03_Preprocessing_and_Training_Data\"\n",
    "tweets_data = pd.read_csv('03_tweets_data.csv', lineterminator='\\n')\n",
    "tweets_data = tweets_data.dropna()\n",
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4e84ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>twitter_volume</th>\n",
       "      <th>likes</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>open_trend</th>\n",
       "      <th>high_trend</th>\n",
       "      <th>low_trend</th>\n",
       "      <th>close_trend</th>\n",
       "      <th>volume_trend</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>1451</td>\n",
       "      <td>3.358270</td>\n",
       "      <td>0.341031</td>\n",
       "      <td>0.166630</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>1551</td>\n",
       "      <td>2.422508</td>\n",
       "      <td>0.336724</td>\n",
       "      <td>0.179263</td>\n",
       "      <td>0.434727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1738</td>\n",
       "      <td>16.589788</td>\n",
       "      <td>0.285005</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.320138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>2072</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>0.308533</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>1912</td>\n",
       "      <td>3.910183</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>0.141816</td>\n",
       "      <td>0.385379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  stock_volume  twitter_volume      likes  Subjectivity  \\\n",
       "Dates                                                                           \n",
       "2022-12-01  148.309998      71250400            1451   3.358270      0.341031   \n",
       "2022-12-02  147.809998      65447400            1551   2.422508      0.336724   \n",
       "2022-12-05  146.630005      68826400            1738  16.589788      0.285005   \n",
       "2022-12-06  142.910004      64727200            2072   3.363636      0.308533   \n",
       "2022-12-07  140.940002      69721100            1912   3.910183      0.306545   \n",
       "\n",
       "            Polarity  Sentiment  open_trend  high_trend  low_trend  \\\n",
       "Dates                                                                \n",
       "2022-12-01  0.166630   0.418668           0           0          0   \n",
       "2022-12-02  0.179263   0.434727           0           0          0   \n",
       "2022-12-05  0.119601   0.320138           1           1          1   \n",
       "2022-12-06  0.138852   0.345839           0           0          0   \n",
       "2022-12-07  0.141816   0.385379           0           0          0   \n",
       "\n",
       "            close_trend  volume_trend Sentiment_Score  \n",
       "Dates                                                  \n",
       "2022-12-01            0             0        Positive  \n",
       "2022-12-02            0             0        Positive  \n",
       "2022-12-05            0             1        Negative  \n",
       "2022-12-06            0             0        Negative  \n",
       "2022-12-07            0             1        Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing merged dataframes from previous notebook \"03_Preprocessing_and_Training_Data\"\n",
    "merged_dataframes = pd.read_csv('03_merged_dataframes.csv', lineterminator='\\n')\n",
    "merged_dataframes = merged_dataframes.set_index('Dates')\n",
    "merged_dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b292498",
   "metadata": {},
   "source": [
    "## 4.2 Method 1: Using overall daily tweet sentiment score to predict adjusted closing price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e59310",
   "metadata": {},
   "source": [
    "This is a classification problem, in unsupervised learning. Here we have used the following classification models:\n",
    "\n",
    "Logistic Regression \\\n",
    "K-Nearest Neighbor (KNN) \\\n",
    "Support vector machine (SVM) \\\n",
    "Random Forest \\\n",
    "K-means Clustering \n",
    "\n",
    "Evaluating the performance of a model by training and testing on the same dataset can lead to the overfitting. Hence the model evaluation is based on splitting the dataset into train and validation set. But the performance of the prediction result depends upon the random choice of the pair of (train,validation) set. Inorder to overcome that, the Cross-Validation procedure is used where under the k-fold CV approach, the training set is split into k smaller sets, where a model is trained using k-1 of the folds as training data and the model is validated on the remaining part.\n",
    "\n",
    "Classification/ Confusion Matrix: This matrix summarizes the correct and incorrect classifications that a classifier produced for a certain dataset. Rows and columns of the classification matrix correspond to the true and predicted classes respectively. The two diagonal cells (upper left, lower right) give the number of correct classifications, where the predicted class coincides with the actual class of the observation. The off diagonal cells gives the count of the misclassification. The classification matrix gives estimates of the true classification and misclassification rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be985148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>twitter_volume</th>\n",
       "      <th>likes</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>open_trend</th>\n",
       "      <th>high_trend</th>\n",
       "      <th>low_trend</th>\n",
       "      <th>close_trend</th>\n",
       "      <th>volume_trend</th>\n",
       "      <th>Sentiment_Score_Negative</th>\n",
       "      <th>Sentiment_Score_Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>1451</td>\n",
       "      <td>3.358270</td>\n",
       "      <td>0.341031</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>1551</td>\n",
       "      <td>2.422508</td>\n",
       "      <td>0.336724</td>\n",
       "      <td>0.434727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1738</td>\n",
       "      <td>16.589788</td>\n",
       "      <td>0.285005</td>\n",
       "      <td>0.320138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>2072</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>0.308533</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>1912</td>\n",
       "      <td>3.910183</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>0.385379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close  stock_volume  twitter_volume      likes  Subjectivity  \\\n",
       "Dates                                                                           \n",
       "2022-12-01  148.309998      71250400            1451   3.358270      0.341031   \n",
       "2022-12-02  147.809998      65447400            1551   2.422508      0.336724   \n",
       "2022-12-05  146.630005      68826400            1738  16.589788      0.285005   \n",
       "2022-12-06  142.910004      64727200            2072   3.363636      0.308533   \n",
       "2022-12-07  140.940002      69721100            1912   3.910183      0.306545   \n",
       "\n",
       "            Sentiment  open_trend  high_trend  low_trend  close_trend  \\\n",
       "Dates                                                                   \n",
       "2022-12-01   0.418668           0           0          0            0   \n",
       "2022-12-02   0.434727           0           0          0            0   \n",
       "2022-12-05   0.320138           1           1          1            0   \n",
       "2022-12-06   0.345839           0           0          0            0   \n",
       "2022-12-07   0.385379           0           0          0            0   \n",
       "\n",
       "            volume_trend  Sentiment_Score_Negative  Sentiment_Score_Positive  \n",
       "Dates                                                                         \n",
       "2022-12-01             0                         0                         1  \n",
       "2022-12-02             0                         0                         1  \n",
       "2022-12-05             1                         1                         0  \n",
       "2022-12-06             0                         1                         0  \n",
       "2022-12-07             1                         1                         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming \"Sentiment_Score\" in the merged_dataframes dataset into binary codes\n",
    "merged_dataframes = pd.get_dummies(merged_dataframes, columns = ['Sentiment_Score'])\n",
    "merged_dataframes = merged_dataframes.drop(['Polarity'], axis=1)\n",
    "merged_dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5d46f",
   "metadata": {},
   "source": [
    "### 4.2.1 Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a2311",
   "metadata": {},
   "source": [
    "1 means adj. closing price rose compare to its yesterday closing price. 0 means it fell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39066c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining our X and y \n",
    "X = merged_dataframes.drop('close_trend', axis=1)\n",
    "y = merged_dataframes['close_trend'].values.reshape(-1,1)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7147e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e09272",
   "metadata": {},
   "source": [
    "### 4.2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f514e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter Accuracy\n",
       "0        0.001      0.8\n",
       "1        0.010      0.8\n",
       "2        0.100      1.0\n",
       "3        1.000      0.8\n",
       "4       10.000      0.8\n",
       "5      100.000      0.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making pipeline\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "table['C_parameter'] = C_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    pipe = make_pipeline( \n",
    "    StandardScaler(),\n",
    "    LogisticRegression(penalty = 'l2', C = i,random_state = 40)\n",
    ")\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred_lr = pipe.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_lr)\n",
    "    j += 1\n",
    "    \n",
    "table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f7192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [0 1]]\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test,y_pred_lr)\n",
    "print(cnf_matrix)\n",
    "accuracy_lr = pipe.score(X_test,y_test)\n",
    "\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2136a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n",
      "Mean cross validation test score: nan\n",
      "Mean cross validation train score: 0.8916666666666667\n",
      "Standard deviation in cv test scores: nan\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test= cross_val_score(pipe,X_test,y_test,cv=2,scoring='roc_auc')\n",
    "cv_scores_train= cross_val_score(pipe,X_train,y_train,cv=2,scoring='roc_auc')\n",
    "print(cv_scores_test)\n",
    "cv_scores_lr_test= cv_scores_test.mean()\n",
    "cv_scores_lr_train= cv_scores_train.mean()\n",
    "cv_scores_std_test_lr= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lr_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lr_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85c791",
   "metadata": {},
   "source": [
    "We can see that the merged_dataframes (tweets combined with stock sentiments) do not yield meaningful results. We could have create more binary codes for other features such as stock_volume, twitter_volukesm. But because our focus is on Natural Language Processing, we will stop here and move on to a text classfication model using Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab7667",
   "metadata": {},
   "source": [
    "## 4.3 Method 2: Using vectorized representation of tweets to predict adjusted closing price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fa85a",
   "metadata": {},
   "source": [
    "Word2Vec is a collection of algorithms which can produce word embeddings. Word embeddings are vectors which describe the semantic meaning of words as points in space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76243f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading pre-trained embedding\n",
    "wv = KeyedVectors.load('glove-twitter-200.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db2e092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>likes</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:43</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>New Yearâs food traditions around the world</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>new yearâ  food tradition  around the world</td>\n",
       "      <td>['new', 'yearâ', 'food', 'tradition', 'around'...</td>\n",
       "      <td>new yearâ food tradition around world</td>\n",
       "      <td>['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...</td>\n",
       "      <td>[-2.31491498e-01  6.51704955e-02  1.90656667e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:32</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Entries &amp;amp; exits Daily! \\nDiscord link belo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 1, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entrie   amp  exit  daily  \\ndi cord link belo...</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>entrie amp exit daily di cord link belowð</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>[ 3.40714295e-02  9.44165736e-02 -8.08280031e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:28</td>\n",
       "      <td>StockJobberOG</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>$AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aapl  m ft   py  t la  amzn  brk b\\n\\n</td>\n",
       "      <td>['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...</td>\n",
       "      <td>aapl ft py la amzn brk b</td>\n",
       "      <td>['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']</td>\n",
       "      <td>[-0.11772024  0.12171325  0.28293075 -0.131354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:11</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>The biggest â and maybe the best â financi...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>the bigge t â and maybe the be t â financi...</td>\n",
       "      <td>['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...</td>\n",
       "      <td>bigge â maybe â financial olution hould u ...</td>\n",
       "      <td>['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...</td>\n",
       "      <td>[-5.57102112e-02  1.48102408e-01  7.54352845e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:28:29</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td># Chatroom interms of \\n\\nalert,calls,Analysis...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 1, '$ ...</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>chatroom interm  of \\n\\nalert call  analy i ...</td>\n",
       "      <td>['chatroom', 'interm', 'of', 'alert', 'call', ...</td>\n",
       "      <td>chatroom interm alert call analy</td>\n",
       "      <td>['chatroom', 'interm', 'alert', 'call', 'analy']</td>\n",
       "      <td>[-1.83531667e-01  2.19245007e-01 -1.40175003e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates      Time            user  likes           source  \\\n",
       "0  2022-12-30  20:29:43  LlcBillionaire      0  Twitter Web App   \n",
       "1  2022-12-30  20:29:32      skitontop1      0  Twitter Web App   \n",
       "2  2022-12-30  20:29:28   StockJobberOG      0  Twitter Web App   \n",
       "3  2022-12-30  20:29:11  LlcBillionaire      0  Twitter Web App   \n",
       "4  2022-12-30  20:28:29      skitontop1      0  Twitter Web App   \n",
       "\n",
       "                                                text  Subjectivity  Polarity  \\\n",
       "0     New Yearâs food traditions around the world       0.454545  0.136364   \n",
       "1  Entries &amp; exits Daily! \\nDiscord link belo...      0.500000  0.300000   \n",
       "2            $AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n      0.000000  0.000000   \n",
       "3  The biggest â and maybe the best â financi...      0.150000  0.500000   \n",
       "4  # Chatroom interms of \\n\\nalert,calls,Analysis...      1.000000  0.600000   \n",
       "\n",
       "   Analysis  Sentiment  ...  mention_count  \\\n",
       "0  Positive        1.0  ...              0   \n",
       "1  Positive        1.0  ...              0   \n",
       "2   Neutral        0.0  ...              0   \n",
       "3  Positive        1.0  ...              0   \n",
       "4  Positive        1.0  ...              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.714286   \n",
       "1  {'! count': 1, '\" count': 0, '# count': 0, '$ ...        7.428571   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.166667   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.200000   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 1, '$ ...        9.200000   \n",
       "\n",
       "  unique_vs_words  stopwords_vs_words  \\\n",
       "0             1.0            0.142857   \n",
       "1             1.0            0.000000   \n",
       "2             1.0            0.000000   \n",
       "3             0.9            0.433333   \n",
       "4             1.0            0.200000   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0     new yearâ  food tradition  around the world    \n",
       "1  entrie   amp  exit  daily  \\ndi cord link belo...   \n",
       "2             aapl  m ft   py  t la  amzn  brk b\\n\\n   \n",
       "3  the bigge t â and maybe the be t â financi...   \n",
       "4    chatroom interm  of \\n\\nalert call  analy i ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['new', 'yearâ', 'food', 'tradition', 'around'...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2  ['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...   \n",
       "3  ['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...   \n",
       "4  ['chatroom', 'interm', 'of', 'alert', 'call', ...   \n",
       "\n",
       "                             tweet_without_stopwords  \\\n",
       "0            new yearâ food tradition around world   \n",
       "1       entrie amp exit daily di cord link belowð   \n",
       "2                           aapl ft py la amzn brk b   \n",
       "3  bigge â maybe â financial olution hould u ...   \n",
       "4                   chatroom interm alert call analy   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  ['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2     ['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']   \n",
       "3  ['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...   \n",
       "4   ['chatroom', 'interm', 'alert', 'call', 'analy']   \n",
       "\n",
       "                                                 vec  \n",
       "0  [-2.31491498e-01  6.51704955e-02  1.90656667e-...  \n",
       "1  [ 3.40714295e-02  9.44165736e-02 -8.08280031e-...  \n",
       "2  [-0.11772024  0.12171325  0.28293075 -0.131354...  \n",
       "3  [-5.57102112e-02  1.48102408e-01  7.54352845e-...  \n",
       "4  [-1.83531667e-01  2.19245007e-01 -1.40175003e-...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f9c32",
   "metadata": {},
   "source": [
    "word2vec can’t create a vector from a word that’s not in its vocabulary. Because of this, we need to specify “if word in model.vocab” when creating the full list of word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d11faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117841,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>likes</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dates, Time, user, likes, source, text, Subjectivity, Polarity, Analysis, Sentiment, char_count, sent_count, mention_count, punct_count, avg_wordlength, unique_vs_words, stopwords_vs_words, clean_text, tokens, tweet_without_stopwords, tweet_lemmatized, vec]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab all the tweets\n",
    "tweets = tweets_data['clean_text']\n",
    "print(tweets.shape)\n",
    "tweets_data[tweets_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eaff4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'food',\n",
       " 'tradition',\n",
       " 'around',\n",
       " 'world',\n",
       " 'entrie',\n",
       " 'amp',\n",
       " 'exit',\n",
       " 'daily',\n",
       " 'di']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of strings, where each string is a tweet\n",
    "tweets_list = [tweet for tweet in tweets]\n",
    "\n",
    "# Collapse the list of strings into a single long string for processing\n",
    "big_tweet_string = ' '.join(tweets_list)\n",
    "\n",
    "# Tokenize the string into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(big_tweet_string)\n",
    "\n",
    "# Remove non-alphabetic tokens, such as punctuation\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "# Filter out stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "words = [word for word in words if not word in stop_words]\n",
    "\n",
    "# Print first 10 words\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75599072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.275540</td>\n",
       "      <td>0.155050</td>\n",
       "      <td>-0.39506</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>-0.43623</td>\n",
       "      <td>0.65921</td>\n",
       "      <td>-0.176150</td>\n",
       "      <td>-0.282610</td>\n",
       "      <td>-0.508480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067459</td>\n",
       "      <td>-0.177820</td>\n",
       "      <td>0.049174</td>\n",
       "      <td>0.26724</td>\n",
       "      <td>-0.061817</td>\n",
       "      <td>0.34782</td>\n",
       "      <td>-0.583470</td>\n",
       "      <td>-0.300400</td>\n",
       "      <td>0.286120</td>\n",
       "      <td>-0.063445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>-0.691750</td>\n",
       "      <td>-0.142590</td>\n",
       "      <td>0.38653</td>\n",
       "      <td>-0.231410</td>\n",
       "      <td>-0.204080</td>\n",
       "      <td>-0.21565</td>\n",
       "      <td>0.77839</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>-0.072446</td>\n",
       "      <td>-0.601340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250490</td>\n",
       "      <td>-0.336230</td>\n",
       "      <td>0.184910</td>\n",
       "      <td>-0.48235</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.24499</td>\n",
       "      <td>-0.244040</td>\n",
       "      <td>0.080309</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.704510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tradition</th>\n",
       "      <td>-0.468270</td>\n",
       "      <td>-0.077617</td>\n",
       "      <td>0.37846</td>\n",
       "      <td>0.035308</td>\n",
       "      <td>-0.092955</td>\n",
       "      <td>-0.27471</td>\n",
       "      <td>0.39512</td>\n",
       "      <td>-0.166380</td>\n",
       "      <td>0.125070</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383770</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>-0.17868</td>\n",
       "      <td>0.054530</td>\n",
       "      <td>0.21030</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>-0.295210</td>\n",
       "      <td>0.294710</td>\n",
       "      <td>-0.601420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>-0.540240</td>\n",
       "      <td>-0.173280</td>\n",
       "      <td>0.49958</td>\n",
       "      <td>-0.219800</td>\n",
       "      <td>0.187340</td>\n",
       "      <td>0.45666</td>\n",
       "      <td>0.86513</td>\n",
       "      <td>-0.286110</td>\n",
       "      <td>-0.450310</td>\n",
       "      <td>0.468560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.204540</td>\n",
       "      <td>-0.503040</td>\n",
       "      <td>-0.14797</td>\n",
       "      <td>0.257760</td>\n",
       "      <td>0.26054</td>\n",
       "      <td>0.322950</td>\n",
       "      <td>0.189860</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>0.073641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.629460</td>\n",
       "      <td>0.27443</td>\n",
       "      <td>-0.364550</td>\n",
       "      <td>0.391890</td>\n",
       "      <td>-0.41298</td>\n",
       "      <td>0.12398</td>\n",
       "      <td>-0.349950</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433180</td>\n",
       "      <td>-0.230370</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>-0.21725</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.61857</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.113410</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>-0.619340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1        2         3         4        5        6    \\\n",
       "new        0.275540  0.155050 -0.39506  0.350000  0.018967 -0.43623  0.65921   \n",
       "food      -0.691750 -0.142590  0.38653 -0.231410 -0.204080 -0.21565  0.77839   \n",
       "tradition -0.468270 -0.077617  0.37846  0.035308 -0.092955 -0.27471  0.39512   \n",
       "around    -0.540240 -0.173280  0.49958 -0.219800  0.187340  0.45666  0.86513   \n",
       "world      0.035771  0.629460  0.27443 -0.364550  0.391890 -0.41298  0.12398   \n",
       "\n",
       "                7         8         9    ...       190       191       192  \\\n",
       "new       -0.176150 -0.282610 -0.508480  ...  0.067459 -0.177820  0.049174   \n",
       "food       0.002269 -0.072446 -0.601340  ... -0.250490 -0.336230  0.184910   \n",
       "tradition -0.166380  0.125070  0.041850  ...  0.383770 -0.020489  0.803810   \n",
       "around    -0.286110 -0.450310  0.468560  ...  0.215700  0.204540 -0.503040   \n",
       "world     -0.349950  0.277250  0.000376  ...  0.433180 -0.230370  0.019838   \n",
       "\n",
       "               193       194      195       196       197       198       199  \n",
       "new        0.26724 -0.061817  0.34782 -0.583470 -0.300400  0.286120 -0.063445  \n",
       "food      -0.48235  0.314250  0.24499 -0.244040  0.080309  0.340600  0.704510  \n",
       "tradition -0.17868  0.054530  0.21030  0.703030 -0.295210  0.294710 -0.601420  \n",
       "around    -0.14797  0.257760  0.26054  0.322950  0.189860  0.022764  0.073641  \n",
       "world     -0.21725  0.168180  0.61857  0.009801  0.113410  0.029805 -0.619340  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "vector_list = [wv[word] for word in words if word in wv.key_to_index]\n",
    "\n",
    "# Create a list of the words corresponding to these vectors\n",
    "words_filtered = [word for word in words if word in wv.key_to_index]\n",
    "\n",
    "# Zip the words together with their vector representations\n",
    "word_vec_zip = zip(words_filtered, vector_list)\n",
    "\n",
    "# Cast to a dict so we can turn it into a DataFrame\n",
    "word_vec_dict = dict(word_vec_zip)\n",
    "df = pd.DataFrame.from_dict(word_vec_dict, orient='index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7d340",
   "metadata": {},
   "source": [
    "### 4.3.1 Dimensionality Reduction with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73812fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920288",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3de1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = classifier.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted_y_test))\n",
    "print(\"Logistic Regression Precision:\", metrics.precision_score(y_test, predicted_y_test, average='micro'))\n",
    "print(\"Logistic Regression Recall:\", metrics.recall_score(y_test, predicted_y_test, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
