{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f4429d",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - 04 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117bd73",
   "metadata": {},
   "source": [
    "The stock market is a focus for investors to maximize their potential profits and consequently, the interest shown from the technical and financial sides in stock market prediction is always on the rise. However, stock market prediction is a problem known for its challenging nature due to its dependency on diverse factors that affect the market, these factors are unpredictable and cannot be taken into consideration such as political variables, and social media effects such as twitter on the stock market.\n",
    "\n",
    "In this final part of this project, we will combine the stock data and its features, with vectorized representation of the tweets for the month of December 2022 to predict whether or not the adjusted closing price at the end of a trading-day is greater than or less than the previous trading-day. Models run are KNN, Logistic Regression, Decision Tree, Random Forest. SVM and ANN.\n",
    "\n",
    "**Link(s) to previous notebook(s)**: \\\n",
    "00_Historical_Data_2014: https://github.com/parisvu07/Springboard_Data_Science/tree/main/Capstone_2_Twitter_Sentiment_Analysis \\\n",
    "01_Data_Wrangling:\n",
    "https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/01_Data_Wrangling.ipynb \\\n",
    "02_Exploratory_Data_Analysis: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/02_Exploratory_Data_Analysis.ipynb \\\n",
    "03_Preprocessing_and_Training_Data: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/03_Preprocessing_and_Training_Data.ipynb\n",
    "\n",
    "Quick fix for \"Unable to render rich display\": copy and paste the notebook link to https://nbviewer.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6f3a3",
   "metadata": {},
   "source": [
    "## 4.1 Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11511d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import spacy\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da83c4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>%_change_Open</th>\n",
       "      <th>%_change_High</th>\n",
       "      <th>%_change_Low</th>\n",
       "      <th>%_change_Close</th>\n",
       "      <th>%_change_Volume</th>\n",
       "      <th>twitter_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>-1.518116</td>\n",
       "      <td>-0.757731</td>\n",
       "      <td>-0.654803</td>\n",
       "      <td>-0.337132</td>\n",
       "      <td>-8.144516</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1.240064</td>\n",
       "      <td>1.972972</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>-0.798317</td>\n",
       "      <td>5.162925</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>-0.473707</td>\n",
       "      <td>-2.398619</td>\n",
       "      <td>-2.641151</td>\n",
       "      <td>-2.536999</td>\n",
       "      <td>-5.955854</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>-3.318151</td>\n",
       "      <td>-2.668030</td>\n",
       "      <td>-1.352874</td>\n",
       "      <td>-1.378491</td>\n",
       "      <td>7.715304</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adj Close  stock_volume  %_change_Open  %_change_High  %_change_Low  \\\n",
       "0  148.309998      71250400            NaN            NaN           NaN   \n",
       "1  147.809998      65447400      -1.518116      -0.757731     -0.654803   \n",
       "2  146.630005      68826400       1.240064       1.972972      0.082396   \n",
       "3  142.910004      64727200      -0.473707      -2.398619     -2.641151   \n",
       "4  140.940002      69721100      -3.318151      -2.668030     -1.352874   \n",
       "\n",
       "   %_change_Close  %_change_Volume  twitter_volume  \n",
       "0             NaN              NaN            1451  \n",
       "1       -0.337132        -8.144516            1551  \n",
       "2       -0.798317         5.162925            1738  \n",
       "3       -2.536999        -5.955854            2072  \n",
       "4       -1.378491         7.715304            1912  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing stock data from notebook \"02_Exploratory_Data_Analysis\"\n",
    "stock_data = pd.read_csv('03_stock_data.csv', encoding='latin-1')\n",
    "stock_data = stock_data.drop('Time', axis=1)\n",
    "stock_data = stock_data.set_index('Dates')\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf864f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:43</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>10 New Yearâs food traditions around the world</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>new yearâ  food tradition  around the world</td>\n",
       "      <td>['new', 'yearâ', 'food', 'tradition', 'around'...</td>\n",
       "      <td>new yearâ food tradition around world</td>\n",
       "      <td>['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...</td>\n",
       "      <td>[-2.31491498e-01  6.51704955e-02  1.90656667e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:32</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Entries &amp;amp; exits Daily! \\nDiscord link belo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 1, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entrie   amp  exit  daily  \\ndi cord link belo...</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>entrie amp exit daily di cord link belowð</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>[ 3.40714295e-02  9.44165736e-02 -8.08280031e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:28</td>\n",
       "      <td>StockJobberOG</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>$AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>aapl  m ft   py  t la  amzn  brk b\\n\\n</td>\n",
       "      <td>['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...</td>\n",
       "      <td>aapl ft py la amzn brk b</td>\n",
       "      <td>['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']</td>\n",
       "      <td>[-0.11772024  0.12171325  0.28293075 -0.131354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:11</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>The biggest â and maybe the best â financi...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.161290</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>the bigge t â and maybe the be t â financi...</td>\n",
       "      <td>['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...</td>\n",
       "      <td>bigge â maybe â financial olution hould u ...</td>\n",
       "      <td>['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...</td>\n",
       "      <td>[-5.57102112e-02  1.48102408e-01  7.54352845e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:28:29</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>#1 Chatroom interms of \\n\\nalert,calls,Analysi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 1, '$ ...</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>chatroom interm  of \\n\\nalert call  analy i ...</td>\n",
       "      <td>['chatroom', 'interm', 'of', 'alert', 'call', ...</td>\n",
       "      <td>chatroom interm alert call analy</td>\n",
       "      <td>['chatroom', 'interm', 'alert', 'call', 'analy']</td>\n",
       "      <td>[-1.83531667e-01  2.19245007e-01 -1.40175003e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates      Time            user           source  \\\n",
       "0  2022-12-30  20:29:43  LlcBillionaire  Twitter Web App   \n",
       "1  2022-12-30  20:29:32      skitontop1  Twitter Web App   \n",
       "2  2022-12-30  20:29:28   StockJobberOG  Twitter Web App   \n",
       "3  2022-12-30  20:29:11  LlcBillionaire  Twitter Web App   \n",
       "4  2022-12-30  20:28:29      skitontop1  Twitter Web App   \n",
       "\n",
       "                                                text  Subjectivity  Polarity  \\\n",
       "0  10 New Yearâs food traditions around the world       0.454545  0.136364   \n",
       "1  Entries &amp; exits Daily! \\nDiscord link belo...      0.500000  0.300000   \n",
       "2            $AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n      0.000000  0.000000   \n",
       "3  The biggest â and maybe the best â financi...      0.150000  0.500000   \n",
       "4  #1 Chatroom interms of \\n\\nalert,calls,Analysi...      1.000000  0.600000   \n",
       "\n",
       "   Analysis  Sentiment  char_count  ...  mention_count  \\\n",
       "0  Positive        1.0          49  ...              0   \n",
       "1  Positive        1.0          52  ...              0   \n",
       "2   Neutral        0.0          37  ...              0   \n",
       "3  Positive        1.0         160  ...              0   \n",
       "4  Positive        1.0          47  ...              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.125000   \n",
       "1  {'! count': 1, '\" count': 0, '# count': 0, '$ ...        7.428571   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.166667   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.161290   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 1, '$ ...        9.400000   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  \\\n",
       "0             8.0         1.000000   \n",
       "1             3.5         1.000000   \n",
       "2             6.0         1.000000   \n",
       "3            31.0         0.903226   \n",
       "4             5.0         1.000000   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0     new yearâ  food tradition  around the world    \n",
       "1  entrie   amp  exit  daily  \\ndi cord link belo...   \n",
       "2             aapl  m ft   py  t la  amzn  brk b\\n\\n   \n",
       "3  the bigge t â and maybe the be t â financi...   \n",
       "4    chatroom interm  of \\n\\nalert call  analy i ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['new', 'yearâ', 'food', 'tradition', 'around'...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2  ['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...   \n",
       "3  ['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...   \n",
       "4  ['chatroom', 'interm', 'of', 'alert', 'call', ...   \n",
       "\n",
       "                             tweet_without_stopwords  \\\n",
       "0            new yearâ food tradition around world   \n",
       "1       entrie amp exit daily di cord link belowð   \n",
       "2                           aapl ft py la amzn brk b   \n",
       "3  bigge â maybe â financial olution hould u ...   \n",
       "4                   chatroom interm alert call analy   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  ['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2     ['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']   \n",
       "3  ['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...   \n",
       "4   ['chatroom', 'interm', 'alert', 'call', 'analy']   \n",
       "\n",
       "                                                 vec  \n",
       "0  [-2.31491498e-01  6.51704955e-02  1.90656667e-...  \n",
       "1  [ 3.40714295e-02  9.44165736e-02 -8.08280031e-...  \n",
       "2  [-0.11772024  0.12171325  0.28293075 -0.131354...  \n",
       "3  [-5.57102112e-02  1.48102408e-01  7.54352845e-...  \n",
       "4  [-1.83531667e-01  2.19245007e-01 -1.40175003e-...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing tweet data from previous notebook \"03_Preprocessing_and_Training_Data\"\n",
    "tweets_data = pd.read_csv('03_tweets_data.csv', lineterminator='\\n')\n",
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aedeb5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>twitter_volume</th>\n",
       "      <th>likes</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>open_trend</th>\n",
       "      <th>high_trend</th>\n",
       "      <th>low_trend</th>\n",
       "      <th>close_trend</th>\n",
       "      <th>volume_trend</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>1451</td>\n",
       "      <td>3.358270</td>\n",
       "      <td>0.341031</td>\n",
       "      <td>0.166630</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>1551</td>\n",
       "      <td>2.422508</td>\n",
       "      <td>0.336724</td>\n",
       "      <td>0.179263</td>\n",
       "      <td>0.434727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1738</td>\n",
       "      <td>16.589788</td>\n",
       "      <td>0.285005</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.320138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>2072</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>0.308533</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>1912</td>\n",
       "      <td>3.910183</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>0.141816</td>\n",
       "      <td>0.385379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adj Close  stock_volume  twitter_volume      likes  Subjectivity  \\\n",
       "0  148.309998      71250400            1451   3.358270      0.341031   \n",
       "1  147.809998      65447400            1551   2.422508      0.336724   \n",
       "2  146.630005      68826400            1738  16.589788      0.285005   \n",
       "3  142.910004      64727200            2072   3.363636      0.308533   \n",
       "4  140.940002      69721100            1912   3.910183      0.306545   \n",
       "\n",
       "   Polarity  Sentiment  open_trend  high_trend  low_trend  close_trend  \\\n",
       "0  0.166630   0.418668           0           0          0            0   \n",
       "1  0.179263   0.434727           0           0          0            0   \n",
       "2  0.119601   0.320138           1           1          1            0   \n",
       "3  0.138852   0.345839           0           0          0            0   \n",
       "4  0.141816   0.385379           0           0          0            0   \n",
       "\n",
       "   volume_trend Sentiment_Score  \n",
       "0             0        Positive  \n",
       "1             0        Positive  \n",
       "2             1        Negative  \n",
       "3             0        Negative  \n",
       "4             1        Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing merged dataframes from previous notebook \"03_Preprocessing_and_Training_Data\"\n",
    "merged_dataframes = pd.read_csv('03_merged_dataframes.csv', lineterminator='\\n')\n",
    "merged_dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab7667",
   "metadata": {},
   "source": [
    "## 4.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920288",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3de1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = classifier.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted_y_test))\n",
    "print(\"Logistic Regression Precision:\", metrics.precision_score(y_test, predicted_y_test, average='micro'))\n",
    "print(\"Logistic Regression Recall:\", metrics.recall_score(y_test, predicted_y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93df20f",
   "metadata": {},
   "source": [
    "### 4.4 Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e25021",
   "metadata": {},
   "source": [
    "This is a classification problem, in unsupervised learning. Here we have used the following classification models:\n",
    "\n",
    "Logistic Regression\n",
    "K-Nearest Neighbor (KNN)\n",
    "Support vector machine (SVM)\n",
    "Random Forest\n",
    "K-means Clustering\n",
    "\n",
    "Evaluating the performance of a model by training and testing on the same dataset can lead to the overfitting. Hence the model evaluation is based on splitting the dataset into train and validation set. But the performance of the prediction result depends upon the random choice of the pair of (train,validation) set. Inorder to overcome that, the Cross-Validation procedure is used where under the k-fold CV approach, the training set is split into k smaller sets, where a model is trained using k-1 of the folds as training data and the model is validated on the remaining part.\n",
    "\n",
    "Classification/ Confusion Matrix: This matrix summarizes the correct and incorrect classifications that a classifier produced for a certain dataset. Rows and columns of the classification matrix correspond to the true and predicted classes respectively. The two diagonal cells (upper left, lower right) give the number of correct classifications, where the predicted class coincides with the actual class of the observation. The off diagonal cells gives the count of the misclassification. The classification matrix gives estimates of the true classification and misclassification rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2e092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf6da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73812fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
