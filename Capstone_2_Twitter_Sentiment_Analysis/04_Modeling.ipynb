{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f4429d",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - 04 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117bd73",
   "metadata": {},
   "source": [
    "The stock market is a focus for investors to maximize their potential profits and consequently, the interest shown from the technical and financial sides in stock market prediction is always on the rise. However, stock market prediction is a problem known for its challenging nature due to its dependency on diverse factors that affect the market, these factors are unpredictable and cannot be taken into consideration such as political variables, and social media effects such as twitter on the stock market.\n",
    "\n",
    "In this final part of this project, we will combine the stock data and its features, with vectorized representation of the tweets for the month of December 2022 to predict whether or not the adjusted closing price at the end of a trading-day is greater than or less than the previous trading-day. Models run are KNN, Logistic Regression, Decision Tree, Random Forest. SVM and ANN.\n",
    "\n",
    "**Link(s) to previous notebook(s)**: \\\n",
    "00_Historical_Data_2014: https://github.com/parisvu07/Springboard_Data_Science/tree/main/Capstone_2_Twitter_Sentiment_Analysis \\\n",
    "01_Data_Wrangling:\n",
    "https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/01_Data_Wrangling.ipynb \\\n",
    "02_Exploratory_Data_Analysis: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/02_Exploratory_Data_Analysis.ipynb \\\n",
    "03_Preprocessing_and_Training_Data: https://github.com/parisvu07/Springboard_Data_Science/blob/main/Capstone_2_Twitter_Sentiment_Analysis/03_Preprocessing_and_Training_Data.ipynb\n",
    "\n",
    "Quick fix for \"Unable to render rich display\": copy and paste the notebook link to https://nbviewer.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6f3a3",
   "metadata": {},
   "source": [
    "## 4.1 Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11511d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "LabeledSentence = gensim.models.doc2vec.TaggedDocument\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import spacy\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da83c4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>%_change_Open</th>\n",
       "      <th>%_change_High</th>\n",
       "      <th>%_change_Low</th>\n",
       "      <th>%_change_Close</th>\n",
       "      <th>%_change_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>148.309998</td>\n",
       "      <td>71250400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>65447400</td>\n",
       "      <td>-1.518116</td>\n",
       "      <td>-0.757731</td>\n",
       "      <td>-0.654803</td>\n",
       "      <td>-0.337132</td>\n",
       "      <td>-8.144516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05</th>\n",
       "      <td>146.630005</td>\n",
       "      <td>68826400</td>\n",
       "      <td>1.240064</td>\n",
       "      <td>1.972972</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>-0.798317</td>\n",
       "      <td>5.162925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>142.910004</td>\n",
       "      <td>64727200</td>\n",
       "      <td>-0.473707</td>\n",
       "      <td>-2.398619</td>\n",
       "      <td>-2.641151</td>\n",
       "      <td>-2.536999</td>\n",
       "      <td>-5.955854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>140.940002</td>\n",
       "      <td>69721100</td>\n",
       "      <td>-3.318151</td>\n",
       "      <td>-2.668030</td>\n",
       "      <td>-1.352874</td>\n",
       "      <td>-1.378491</td>\n",
       "      <td>7.715304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close    Volume  %_change_Open  %_change_High  %_change_Low  \\\n",
       "Dates                                                                          \n",
       "2022-12-01  148.309998  71250400            NaN            NaN           NaN   \n",
       "2022-12-02  147.809998  65447400      -1.518116      -0.757731     -0.654803   \n",
       "2022-12-05  146.630005  68826400       1.240064       1.972972      0.082396   \n",
       "2022-12-06  142.910004  64727200      -0.473707      -2.398619     -2.641151   \n",
       "2022-12-07  140.940002  69721100      -3.318151      -2.668030     -1.352874   \n",
       "\n",
       "            %_change_Close  %_change_Volume  \n",
       "Dates                                        \n",
       "2022-12-01             NaN              NaN  \n",
       "2022-12-02       -0.337132        -8.144516  \n",
       "2022-12-05       -0.798317         5.162925  \n",
       "2022-12-06       -2.536999        -5.955854  \n",
       "2022-12-07       -1.378491         7.715304  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing stock data from notebook \"02_Exploratory_Data_Analysis\"\n",
    "stock_data = pd.read_csv('/Users/user/Documents/Springboard_Data_Science/Capstone_2_Twitter_Sentiment_Analysis/Data/03_stock_data.csv', encoding='latin-1')\n",
    "stock_data = eda_stock_data.set_index('Dates')\n",
    "stock_data = eda_stock_data.drop('Time', axis=1)\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf864f4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>user</th>\n",
       "      <th>likes</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>avg_sentlength</th>\n",
       "      <th>unique_vs_words</th>\n",
       "      <th>stopwords_vs_words</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:43</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>10 New Yearâs food traditions around the world</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>new yearâ  food tradition  around the world</td>\n",
       "      <td>['new', 'yearâ', 'food', 'tradition', 'around'...</td>\n",
       "      <td>new yearâ food tradition around world</td>\n",
       "      <td>['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:32</td>\n",
       "      <td>skitontop1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Entries &amp;amp; exits Daily! \\nDiscord link belo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 1, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entrie   amp  exit  daily  \\ndi cord link belo...</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "      <td>entrie amp exit daily di cord link belowð</td>\n",
       "      <td>['entrie', 'amp', 'exit', 'daily', 'di', 'cord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:28</td>\n",
       "      <td>StockJobberOG</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>$AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>aapl  m ft   py  t la  amzn  brk b\\n\\n</td>\n",
       "      <td>['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...</td>\n",
       "      <td>aapl ft py la amzn brk b</td>\n",
       "      <td>['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:20</td>\n",
       "      <td>ItsJennyJ</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>@Apple I have an Apple ipod from 2012.\\nI'd li...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 2, '$ ...</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>i have an apple ipod from  \\ni d like to  tar...</td>\n",
       "      <td>['i', 'have', 'an', 'apple', 'ipod', 'from', '...</td>\n",
       "      <td>apple ipod like tart u ing apple id order tart...</td>\n",
       "      <td>['apple', 'ipod', 'like', 'tart', 'u', 'ing', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>20:29:11</td>\n",
       "      <td>LlcBillionaire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>The biggest â and maybe the best â financi...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'! count': 0, '\" count': 0, '# count': 0, '$ ...</td>\n",
       "      <td>5.161290</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>the bigge t â and maybe the be t â financi...</td>\n",
       "      <td>['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...</td>\n",
       "      <td>bigge â maybe â financial olution hould u ...</td>\n",
       "      <td>['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates      Time            user  likes               source  \\\n",
       "0  2022-12-30  20:29:43  LlcBillionaire      0      Twitter Web App   \n",
       "1  2022-12-30  20:29:32      skitontop1      0      Twitter Web App   \n",
       "2  2022-12-30  20:29:28   StockJobberOG      0      Twitter Web App   \n",
       "3  2022-12-30  20:29:20       ItsJennyJ      0  Twitter for Android   \n",
       "4  2022-12-30  20:29:11  LlcBillionaire      0      Twitter Web App   \n",
       "\n",
       "                                                text  Subjectivity  Polarity  \\\n",
       "0  10 New Yearâs food traditions around the world       0.454545  0.136364   \n",
       "1  Entries &amp; exits Daily! \\nDiscord link belo...      0.500000  0.300000   \n",
       "2            $AAPL $MSFT $SPY $TSLA $AMZN $BRK.B\\n\\n      0.000000  0.000000   \n",
       "3  @Apple I have an Apple ipod from 2012.\\nI'd li...      0.000000  0.000000   \n",
       "4  The biggest â and maybe the best â financi...      0.150000  0.500000   \n",
       "\n",
       "   Analysis  Sentiment  ...  mention_count  \\\n",
       "0  Positive        1.0  ...              0   \n",
       "1  Positive        1.0  ...              0   \n",
       "2   Neutral        0.0  ...              0   \n",
       "3   Neutral        0.0  ...              0   \n",
       "4  Positive        1.0  ...              0   \n",
       "\n",
       "                                         punct_count  avg_wordlength  \\\n",
       "0  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.125000   \n",
       "1  {'! count': 1, '\" count': 0, '# count': 0, '$ ...        7.428571   \n",
       "2  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        6.166667   \n",
       "3  {'! count': 0, '\" count': 0, '# count': 2, '$ ...        4.705882   \n",
       "4  {'! count': 0, '\" count': 0, '# count': 0, '$ ...        5.161290   \n",
       "\n",
       "   avg_sentlength  unique_vs_words  stopwords_vs_words  \\\n",
       "0             8.0         1.000000            0.125000   \n",
       "1             3.5         1.000000            0.000000   \n",
       "2             6.0         1.000000            0.000000   \n",
       "3             6.8         0.794118            0.411765   \n",
       "4            31.0         0.903226            0.419355   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0     new yearâ  food tradition  around the world    \n",
       "1  entrie   amp  exit  daily  \\ndi cord link belo...   \n",
       "2             aapl  m ft   py  t la  amzn  brk b\\n\\n   \n",
       "3   i have an apple ipod from  \\ni d like to  tar...   \n",
       "4  the bigge t â and maybe the be t â financi...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['new', 'yearâ', 'food', 'tradition', 'around'...   \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...   \n",
       "2  ['aapl', 'm', 'ft', 'py', 't', 'la', 'amzn', '...   \n",
       "3  ['i', 'have', 'an', 'apple', 'ipod', 'from', '...   \n",
       "4  ['the', 'bigge', 't', 'â', 'and', 'maybe', 'th...   \n",
       "\n",
       "                             tweet_without_stopwords  \\\n",
       "0            new yearâ food tradition around world   \n",
       "1       entrie amp exit daily di cord link belowð   \n",
       "2                           aapl ft py la amzn brk b   \n",
       "3  apple ipod like tart u ing apple id order tart...   \n",
       "4  bigge â maybe â financial olution hould u ...   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  ['new', 'yearâ\\x80\\x99', 'food', 'tradition', ...  \n",
       "1  ['entrie', 'amp', 'exit', 'daily', 'di', 'cord...  \n",
       "2     ['aapl', 'ft', 'py', 'la', 'amzn', 'brk', 'b']  \n",
       "3  ['apple', 'ipod', 'like', 'tart', 'u', 'ing', ...  \n",
       "4  ['bigge', 'â\\x80\\x94', 'maybe', 'â\\x80\\x94', '...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing tweet data from previous notebook \"03_Preprocessing_and_Training_Data\"\n",
    "trading_hours_tweets = pd.read_csv('/Users/user/Documents/Springboard_Data_Science/Capstone_2_Twitter_Sentiment_Analysis/Data/03_tweets_data.csv', lineterminator='\\n')\n",
    "trading_hours_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab7667",
   "metadata": {},
   "source": [
    "## 4.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b920288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3de1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.637923531240286\n",
      "Logistic Regression Precision: 0.637923531240286\n",
      "Logistic Regression Recall: 0.637923531240286\n"
     ]
    }
   ],
   "source": [
    "predicted_y_test = classifier.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted_y_test))\n",
    "print(\"Logistic Regression Precision:\", metrics.precision_score(y_test, predicted_y_test, average='micro'))\n",
    "print(\"Logistic Regression Recall:\", metrics.recall_score(y_test, predicted_y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93df20f",
   "metadata": {},
   "source": [
    "### 4.4 Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f66ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2e092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf6da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73812fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
